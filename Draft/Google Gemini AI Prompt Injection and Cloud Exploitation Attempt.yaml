title: Google Gemini AI Prompt Injection and Cloud Exploitation Attempt
id: 
status: draft
description: Detects potential prompt injection attacks and cloud exploitation attempts targeting Google Gemini AI services, which could lead to unauthorized access, data exfiltration, or cloud resource compromise
references:
  - https://thehackernews.com/2025/09/researchers-disclose-google-gemini-ai.html
  - https://arxiv.org/abs/2302.12173
  - https://learnprompting.org/docs/prompt_injection
author: 
date: 2024-01-20
logsource:
  category: application
  product: google
  service: gemini
detection:
  selection:
    - event.action: 
        - 'api_call'
        - 'prompt_execution'
        - 'model_inference'
    - request.method: 'POST'
    - request.path|contains: 
        - '/v1/models/gemini'
        - '/generateContent'
        - '/streamGenerateContent'
    - request.body|contains|all:
        - 'ignore'
        - 'previous'
        - 'instructions'
    - request.body|contains|any:
        - 'system'
        - 'role'
        - 'assistant'
        - 'developer'
  condition: selection
falsepositives:
  - Legitimate AI research and testing activities
  - AI development and debugging sessions
  - Security testing and red team exercises
  - Recommended to whitelist known AI development IP ranges and service accounts
level: high
tags:
  - attack.t1190
  - attack.t1588
  - attack.t1059
  - cve.2025.gemini
  - ai.security
  - prompt.injection
  - cloud.exploitation